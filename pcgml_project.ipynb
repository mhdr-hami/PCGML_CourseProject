{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8dl2C2Sj4KK"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJvo9ALZkL5p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfl3Yi4TkO6Y"
      },
      "outputs": [],
      "source": [
        "class VectorQuantizer(layers.Layer):\n",
        "  def __init__(self, num_embeddings, embedding_dim, beta=0.25, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.num_embeddings = num_embeddings\n",
        "\n",
        "    # beta best kept betweek [0.25, 2]\n",
        "    self.beta = beta\n",
        "\n",
        "\n",
        "    # init embeddings\n",
        "    w_init = tf.random_uniform_initializer()\n",
        "    self.embeddings = tf.Variable(\n",
        "        initial_value = w_init(\n",
        "            shape=(self.embedding_dim, self.num_embeddings), dtype='float32'\n",
        "        ),\n",
        "        trainable=True,\n",
        "        name='embedding_vqvae',\n",
        "    )\n",
        "\n",
        "  def call(self, x):\n",
        "    input_shape = tf.shape(x)\n",
        "    flattened = tf.reshape(x, [-1, self.embedding_dim])\n",
        "\n",
        "    # Quantization\n",
        "    encoding_indices = self.get_code_indices(flattened)\n",
        "    encodings = tf.one_hot(encoding_indices, self.num_embeddings)\n",
        "    quantized = tf.matmul(encodings, self.embeddings, transpose_b=True)\n",
        "\n",
        "    quantized = tf.reshape(quantized, input_shape)\n",
        "\n",
        "\n",
        "    commitment_loss = tf.reduce_mean((tf.stop_gradient(quantized) - x) ** 2)\n",
        "    codebook_loss = tf.reduce_mean((quantized - tf.stop_gradient(x)) ** 2)\n",
        "    self.add_loss(self.beta * commitment_loss + codebook_loss)\n",
        "\n",
        "    quantized = x + tf.stop_gradient(quantized - x)\n",
        "\n",
        "    return quantized\n",
        "\n",
        "\n",
        "  def get_code_indices(self, flattened_inputs):\n",
        "\n",
        "    similarity = tf.matmul(flattened_inputs, self.embeddings)\n",
        "    distances = (\n",
        "        tf.reduce_sum(flattened_inputs ** 2, axis=1, keepdims=True)\n",
        "        + tf.reduce_sum(self.embeddings ** 2, axis = 0)\n",
        "        - 2 * similarity\n",
        "    )\n",
        "\n",
        "    encoding_indices = tf.argmin(distances, axis=1)\n",
        "\n",
        "    return encoding_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPdmkfd_kq77"
      },
      "outputs": [],
      "source": [
        "def get_encoder(latent_dim=16):\n",
        "    encoder_inputs = keras.Input(shape=(16, 16, 18))\n",
        "    x = layers.Conv2D(16, 3, activation=\"relu\", padding='same')(encoder_inputs)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Conv2D(32, 3, activation=\"relu\", padding='same')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    encoder_outputs = layers.Conv2D(latent_dim, 1, padding=\"same\")(x)\n",
        "    return keras.Model(encoder_inputs, encoder_outputs, name=\"encoder\")\n",
        "\n",
        "\n",
        "def get_decoder(latent_dim=16):\n",
        "    latent_inputs = keras.Input(shape=get_encoder(latent_dim).output.shape[1:])\n",
        "    x = layers.UpSampling2D()(latent_inputs)\n",
        "    x = layers.Conv2DTranspose(32, 3, activation=\"relu\", padding='same')(x)\n",
        "    x = layers.UpSampling2D()(x)\n",
        "    x = layers.Conv2DTranspose(16, 3, activation=\"relu\", padding='same')(x)\n",
        "    decoder_outputs = layers.Conv2DTranspose(18, 3, padding=\"same\")(x)\n",
        "    return keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ4QV-P3ofmb",
        "outputId": "b71997ee-1cdd-412a-8482-a81e6b54c70a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vq_vae\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 16, 16, 18)]      0         \n",
            "                                                                 \n",
            " encoder (Functional)        (None, 4, 4, 16)          7776      \n",
            "                                                                 \n",
            " vector_quantizer (VectorQua  (None, 4, 4, 16)         1024      \n",
            " ntizer)                                                         \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 16, 16, 18)        11874     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,674\n",
            "Trainable params: 20,674\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def get_vqvae(latent_dim=16, num_embeddings=64):\n",
        "\n",
        "    vq_layer = VectorQuantizer(num_embeddings, latent_dim, name=\"vector_quantizer\")\n",
        "    #print(vq_layer.embeddings[:])\n",
        "    encoder = get_encoder(latent_dim)\n",
        "    decoder = get_decoder(latent_dim)\n",
        "    inputs = keras.Input(shape=(16, 16, 18))\n",
        "    encoder_outputs = encoder(inputs)\n",
        "    quantized_latents = vq_layer(encoder_outputs)\n",
        "    reconstructions = decoder(quantized_latents)\n",
        "    return keras.Model(inputs, reconstructions, name=\"vq_vae\")\n",
        "\n",
        "\n",
        "get_vqvae().summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Oa-RO6TpJ6M"
      },
      "outputs": [],
      "source": [
        "class VQVAETrainer(keras.models.Model):\n",
        "  def __init__(self, train_variance, latent_dim = 16, num_embeddings=64, **kwargs):\n",
        "    super(VQVAETrainer, self).__init__(**kwargs)\n",
        "    self.train_variance = train_variance\n",
        "    self.latent_dim = latent_dim\n",
        "    self.num_embeddings = num_embeddings\n",
        "\n",
        "    self.vqvae= get_vqvae(self.latent_dim, self.num_embeddings)\n",
        "\n",
        "    self.total_loss_tracker = keras.metrics.Mean(name='total_loss')\n",
        "    self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "        name='reconstruction_loss'\n",
        "    )\n",
        "    self.vq_loss_tracker = keras.metrics.Mean(name='vq_loss')\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [\n",
        "        self.total_loss_tracker,\n",
        "        self.reconstruction_loss_tracker,\n",
        "        self.vq_loss_tracker,\n",
        "    ]\n",
        "\n",
        "  def train_step(self, x):\n",
        "    with tf.GradientTape() as tape:\n",
        "      reconstruction = self.vqvae(x)\n",
        "\n",
        "      reconstruction_loss = (\n",
        "          tf.reduce_mean((x - reconstruction) ** 2) / self.train_variance\n",
        "      )\n",
        "      total_loss = reconstruction_loss + sum(self.vqvae.losses)\n",
        "\n",
        "    grads = tape.gradient(total_loss, self.vqvae.trainable_variables)\n",
        "    self.optimizer.apply_gradients(zip(grads, self.vqvae.trainable_variables))\n",
        "\n",
        "    self.total_loss_tracker.update_state(total_loss)\n",
        "    self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "    self.vq_loss_tracker.update_state(sum(self.vqvae.losses))\n",
        "\n",
        "\n",
        "    return {\n",
        "        'loss': self.total_loss_tracker.result(),\n",
        "        'reconstruction_loss': self.reconstruction_loss_tracker.result(),\n",
        "        'vqvae_loss': self.vq_loss_tracker.result(),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp8xQEg6r1c3",
        "outputId": "8ebb865e-78d1-4e82-ce0c-55e63aecdc3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'TheVGLC' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# get vglc data\n",
        "\n",
        "!git clone https://github.com/TheVGLC/TheVGLC.git\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def text_2_mat(s):\n",
        "  mat = []\n",
        "  for row in s.split('\\n'):\n",
        "    temp = []\n",
        "    for item in row:\n",
        "      temp.append(item)\n",
        "\n",
        "    mat.append(temp)\n",
        "\n",
        "  return mat\n",
        "\n",
        "\n",
        "def mat_2_text(arr):\n",
        "  text = ''\n",
        "  for row in arr:\n",
        "    for item in row:\n",
        "      text += item\n",
        "    text += '\\n'\n",
        "  return text[:-1]\n",
        "\n",
        "\n",
        "def get_chunks(mat):\n",
        "\n",
        "  chunks = []\n",
        "\n",
        "  if len(mat.shape) != 2:\n",
        "    raise ValueError\n",
        "\n",
        "  smaller_axis = np.argmin(mat.shape)\n",
        "  smaller_range = np.min(mat.shape)\n",
        "\n",
        "  if smaller_axis == 0:\n",
        "    mat = np.transpose(mat, (1,0))\n",
        "\n",
        "  for i in range(len(mat) - smaller_range):\n",
        "    chunk = mat[i:i+smaller_range, :]\n",
        "\n",
        "    if smaller_axis == 0:\n",
        "      chunk = np.transpose(chunk, (1,0))\n",
        "\n",
        "    chunks.append(chunk)\n",
        "\n",
        "  return chunks\n",
        "\n",
        "\n",
        "\n",
        "def one_hot(x):\n",
        "\n",
        "  new_x = np.zeros(list(x.shape) + [len(replacement_table)])\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      new_x[i, j, :] = replacement_table[x[i,j]]\n",
        "\n",
        "  return new_x\n",
        "\n",
        "\n",
        "\n",
        "def chunk_2_text(chunk):\n",
        "  mat = np.zeros(chunk.shape[:-1]).astype('str')\n",
        "  for i in range(chunk.shape[0]):\n",
        "    for j in range(chunk.shape[1]):\n",
        "      mat[i,j] = replacement_table_inverse[np.argmax(chunk[i,j,:])]\n",
        "\n",
        "  return mat_2_text(mat)\n",
        "\n",
        "\n",
        "\n",
        "def print_side_by_side(chunk_1, chunk_2):\n",
        "  mat_1 = np.zeros(chunk_1.shape[:-1]).astype('str')\n",
        "  for i in range(chunk_1.shape[0]):\n",
        "    for j in range(chunk_1.shape[1]):\n",
        "      mat_1[i,j] = replacement_table_inverse[np.argmax(chunk_1[i,j,:])]\n",
        "\n",
        "  mat_2 = np.zeros(chunk_2.shape[:-1]).astype('str')\n",
        "  for i in range(chunk_2.shape[0]):\n",
        "    for j in range(chunk_2.shape[1]):\n",
        "      mat_2[i,j] = replacement_table_inverse[np.argmax(chunk_2[i,j,:])]\n",
        "\n",
        "  mat_mid = np.full((chunk_1.shape[0], chunk_1.shape[1]), ' ').astype('str')\n",
        "\n",
        "\n",
        "  return mat_2_text(np.concatenate((mat_1, mat_mid, mat_2), axis=1))\n",
        "\n",
        "def get_smb_data():\n",
        "  path_to_data = '/content/TheVGLC/Super Mario Bros/Processed/'\n",
        "\n",
        "  data_chunks = []\n",
        "\n",
        "  for file_name in os.listdir(path_to_data):\n",
        "    with open(path_to_data + file_name, 'r') as f:\n",
        "      s = f.read()\n",
        "      mat1 = np.array(text_2_mat(s)[:-1]).astype('str')\n",
        "      mat2 = np.full((2, mat1.shape[1]), fill_value='-')\n",
        "      mat = np.concatenate((mat2, mat1), axis=0)\n",
        "      data_chunks += get_chunks(mat)\n",
        "\n",
        "  one_hot_chunks = []\n",
        "  for chunk in data_chunks:\n",
        "    one_hot_chunks.append(one_hot(chunk))\n",
        "\n",
        "\n",
        "  print('Extracted {} data points with shape {}'.format(len(one_hot_chunks), one_hot_chunks[0].shape))\n",
        "\n",
        "\n",
        "  raw_data = np.stack(one_hot_chunks)\n",
        "  np.random.shuffle(raw_data)\n",
        "\n",
        "\n",
        "  print('shape:{}  min:{}  max:{}  dtype:{}'.format(raw_data.shape, raw_data.min(), raw_data.max(), raw_data.dtype))\n",
        "\n",
        "  return raw_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOin8s3OncWf"
      },
      "outputs": [],
      "source": [
        "def get_ki_data():\n",
        "  path_to_data = '/content/TheVGLC/Kid Icarus/Processed/'\n",
        "\n",
        "  data_chunks = []\n",
        "\n",
        "  for file_name in os.listdir(path_to_data):\n",
        "    with open(path_to_data + file_name, 'r') as f:\n",
        "      s = f.read()\n",
        "      mat = np.array(text_2_mat(s)[:-1]).astype('str')\n",
        "      data_chunks += get_chunks(mat)\n",
        "\n",
        "  one_hot_chunks = []\n",
        "  for chunk in data_chunks:\n",
        "    one_hot_chunks.append(one_hot(chunk))\n",
        "\n",
        "\n",
        "  print('Extracted {} data points with shape {}'.format(len(one_hot_chunks), one_hot_chunks[0].shape))\n",
        "\n",
        "\n",
        "  raw_data = np.stack(one_hot_chunks)\n",
        "  np.random.shuffle(raw_data)\n",
        "\n",
        "\n",
        "  print('shape:{}  min:{}  max:{}  dtype:{}'.format(raw_data.shape, raw_data.min(), raw_data.max(), raw_data.dtype))\n",
        "\n",
        "  return raw_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGKyHUYPmEjV"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "we do not need all these==> just elements of map 1-1\n",
        "'''\n",
        "\n",
        "replacement_table = {\n",
        "         \"X\": None,\n",
        "        \"S\" : None,\n",
        "        \"-\" : None,\n",
        "        \"?\" : None,\n",
        "        \"Q\" : None,\n",
        "        \"E\" : None,\n",
        "        \"<\" : None,\n",
        "        \">\" : None,\n",
        "        \"[\" : None,\n",
        "        \"]\" : None,\n",
        "        \"o\" : None,\n",
        "        \"B\" : None,\n",
        "        \"b\" : None,\n",
        "        \"#\" : None,\n",
        "        \"D\" : None,\n",
        "        \"H\" : None,\n",
        "        \"M\" : None,\n",
        "        \"T\" : None,\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "for i, v in enumerate(replacement_table):\n",
        "  replacement_table[v] = np.array([0] * i + [1] + [0] * (len(replacement_table) - i - 1))\n",
        "\n",
        "replacement_table_inverse = list(replacement_table.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd7BkqlWmawo",
        "outputId": "fbca5a98-97d5-4a33-bc7a-e6818b5bbd97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'X': array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'S': array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), '-': array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), '?': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'Q': array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'E': array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), '<': array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), '>': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), '[': array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ']': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), 'o': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]), 'B': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]), 'b': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]), '#': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), 'D': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]), 'H': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]), 'M': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]), 'T': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])}\n",
            "['X', 'S', '-', '?', 'Q', 'E', '<', '>', '[', ']', 'o', 'B', 'b', '#', 'D', 'H', 'M', 'T']\n"
          ]
        }
      ],
      "source": [
        "print(replacement_table)\n",
        "print(replacement_table_inverse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "sDZcOJe1nnnG",
        "outputId": "03f2435d-d58f-4896-9273-eb4873dc9780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted 2683 data points with shape (16, 16, 18)\n",
            "shape:(2683, 16, 16, 18)  min:0.0  max:1.0  dtype:float64\n",
            "Extracted 1153 data points with shape (16, 16, 18)\n",
            "shape:(1153, 16, 16, 18)  min:0.0  max:1.0  dtype:float64\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nwe need to have the same shape\\n'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smb_data = get_smb_data()\n",
        "ki_data = get_ki_data()\n",
        "\n",
        "'''\n",
        "we need to have the same shape\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF2pVbLaoCPA"
      },
      "outputs": [],
      "source": [
        "raw_data = np.concatenate([smb_data, ki_data])\n",
        "np.random.shuffle(raw_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdmwWySRpINx"
      },
      "outputs": [],
      "source": [
        "x_train = raw_data[:]\n",
        "x_test = x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRpLb__hI0L8",
        "outputId": "0ad4fb6d-6332-44a0-b51f-9ab09913a34e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3836, 16, 16, 18)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O34jrbdvxsCD",
        "outputId": "458f862c-80ec-49dc-eaa6-cc0f2b1e6205"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3836, 16, 16, 18)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qtbf1uE4W2nX"
      },
      "outputs": [],
      "source": [
        "data_variance = x_train.var()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaiAR_eo3r1V",
        "outputId": "7dca64ca-90bd-4e8b-f4f5-35ab0bd9bf8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2683, 16, 16, 18)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smb_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuiu6L7j3lcG",
        "outputId": "d9e00aa5-4766-4ebb-fca4-bc05b5e72f43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-90500cfa9d43>:2: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  smb_data_samples = smb_data[[smb_data_indexes]]\n"
          ]
        }
      ],
      "source": [
        "smb_data_indexes=np.random.choice(len(smb_data),100)\n",
        "smb_data_samples = smb_data[[smb_data_indexes]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ-mkb9V4V1F",
        "outputId": "b2a1c889-361f-451a-86fa-635a35a432cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 16, 16, 18)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smb_data_samples.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xRO73TU4lkQ",
        "outputId": "57b9a1ce-c934-419b-faef-a7f37b5b5bc3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-555e3f49e4c8>:2: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  ki_data_samples = ki_data[[ki_data_indexes]]\n"
          ]
        }
      ],
      "source": [
        "ki_data_indexes=np.random.choice(len(ki_data),100)\n",
        "ki_data_samples = ki_data[[ki_data_indexes]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNDvEf3v40Fq",
        "outputId": "e8077070-3ede-4b27-e739-a37585aef6fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 16, 16, 18)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ki_data_samples.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTjnodF848tQ"
      },
      "outputs": [],
      "source": [
        "init_data = np.concatenate([smb_data_samples,ki_data_samples])\n",
        "np.random.shuffle(init_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wroxkmY5dzv"
      },
      "outputs": [],
      "source": [
        "data_variance = init_data.var()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEV8-xMc6FYt",
        "outputId": "c7cfcafb-a06b-457b-d365-aea5e8206693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "120/120 [==============================] - 7s 55ms/step - loss: 0.7417 - reconstruction_loss: 0.3644 - vqvae_loss: 0.2164\n",
            "Epoch 2/10\n",
            "120/120 [==============================] - 7s 56ms/step - loss: 0.4893 - reconstruction_loss: 0.2467 - vqvae_loss: 0.2383\n",
            "Epoch 3/10\n",
            "120/120 [==============================] - 7s 55ms/step - loss: 0.6159 - reconstruction_loss: 0.2238 - vqvae_loss: 0.3869\n",
            "Epoch 4/10\n",
            "120/120 [==============================] - 7s 55ms/step - loss: 0.3992 - reconstruction_loss: 0.1977 - vqvae_loss: 0.2005\n",
            "Epoch 5/10\n",
            "120/120 [==============================] - 7s 55ms/step - loss: 0.3903 - reconstruction_loss: 0.1838 - vqvae_loss: 0.2027\n",
            "Epoch 6/10\n",
            "120/120 [==============================] - 7s 56ms/step - loss: 0.3366 - reconstruction_loss: 0.1704 - vqvae_loss: 0.1587\n",
            "Epoch 7/10\n",
            "120/120 [==============================] - 7s 55ms/step - loss: 0.2866 - reconstruction_loss: 0.1629 - vqvae_loss: 0.1237\n",
            "Epoch 8/10\n",
            "120/120 [==============================] - 8s 66ms/step - loss: 0.2850 - reconstruction_loss: 0.1530 - vqvae_loss: 0.1288\n",
            "Epoch 9/10\n",
            "120/120 [==============================] - 7s 55ms/step - loss: 0.2687 - reconstruction_loss: 0.1452 - vqvae_loss: 0.1217\n",
            "Epoch 10/10\n",
            "120/120 [==============================] - 7s 55ms/step - loss: 0.2605 - reconstruction_loss: 0.1403 - vqvae_loss: 0.1222\n"
          ]
        }
      ],
      "source": [
        "vqvae_trainer = VQVAETrainer(data_variance, latent_dim=16, num_embeddings=64)\n",
        "vqvae_trainer.compile(optimizer=keras.optimizers.Adam())\n",
        "vqvae_trainer.fit(x_train, epochs=10, batch_size=32)\n",
        "vqvae_trainer.vqvae.save_weights('model_new1.h5')\n",
        "vq_layer = vqvae_trainer.vqvae.layers[2]\n",
        "emb1=vq_layer.embeddings\n",
        "a = np.array(emb1)\n",
        "np.save('codebook_new1',a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n64t1SCF6goo",
        "outputId": "3258fbff-98d8-4d8b-c1ba-68da17702127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 1s 18ms/step\n"
          ]
        }
      ],
      "source": [
        "trained_vqvae_model = vqvae_trainer.vqvae\n",
        "\n",
        "input = init_data\n",
        "\n",
        "input_layer = vqvae_trainer.vqvae.layers[0]\n",
        "encoder_layer = vqvae_trainer.vqvae.layers[1]\n",
        "vq_layer = vqvae_trainer.vqvae.layers[2]\n",
        "decoder_layer = vqvae_trainer.vqvae.layers[3]\n",
        "\n",
        "\n",
        "input_layer_x = input_layer(input)\n",
        "encoder_layer_x = encoder_layer(input_layer_x)\n",
        "\n",
        "vq_layer_x = vq_layer(encoder_layer_x)     ### For GA we need this !\n",
        "\n",
        "decoder_layer_x = decoder_layer(vq_layer_x)\n",
        "direct_output = trained_vqvae_model.predict(input) ## decoder output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKnhKto-7uAj",
        "outputId": "3d8ab16a-904a-45b2-fa34-b11be2784def"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4, 4, 16)\n",
            "[[[0.3613823354244232, 0.20851649343967438, 0.10268021374940872, -0.5401704907417297, -0.20404848456382751, -0.5413349866867065, -0.6137734651565552, 0.36509108543395996, 0.46239104866981506, -0.29573532938957214, -0.4568139314651489, 0.14603693783283234, -0.1900632381439209, 0.46691274642944336, -0.43053674697875977, -0.06848406046628952], [0.5815469622612, 0.8193275332450867, -0.043671589344739914, -0.23612618446350098, 0.1987346112728119, -0.370801717042923, -0.4949207007884979, 0.6815537214279175, 0.5220808386802673, -0.5869254469871521, -0.2245737463235855, 0.16372837126255035, -0.21941831707954407, 0.2997949421405792, -0.6521328687667847, -0.18093407154083252], [0.5815469622612, 0.8193275332450867, -0.04367157816886902, -0.23612618446350098, 0.1987346112728119, -0.370801717042923, -0.4949207007884979, 0.6815537214279175, 0.5220808386802673, -0.5869254469871521, -0.2245737463235855, 0.16372835636138916, -0.21941831707954407, 0.2997949421405792, -0.6521328687667847, -0.18093407154083252], [0.3613823354244232, 0.20851649343967438, 0.10268021374940872, -0.5401704907417297, -0.20404848456382751, -0.5413349866867065, -0.6137734651565552, 0.36509108543395996, 0.46239104866981506, -0.29573532938957214, -0.4568139314651489, 0.14603693783283234, -0.1900632381439209, 0.46691274642944336, -0.43053674697875977, -0.06848406046628952], [-0.009599536657333374, 0.07957787066698074, -0.5278271436691284, -0.16804951429367065, 0.2429427057504654, -0.06411716341972351, -0.17453938722610474, 0.77238929271698, -0.15387721359729767, -0.049077801406383514, -0.42700380086898804, 0.2612093687057495, -0.2767356038093567, -0.23993991315364838, -0.4380418062210083, 0.5309122204780579], [-0.38442307710647583, 0.4865400195121765, 0.6580949425697327, -0.14802426099777222, -0.10401082038879395, -0.5258643627166748, -0.6871569752693176, 0.804716169834137, 0.13751782476902008, 0.27511703968048096, -0.39235571026802063, -0.35199618339538574, -0.43947771191596985, -0.11364033818244934, 0.07894590497016907, -0.5208229422569275], [-0.8553060293197632, -0.8682360053062439, -0.22539204359054565, 0.15054023265838623, -0.20229168236255646, 0.14937442541122437, -0.5362167358398438, 0.30514803528785706, -0.33539879322052, 1.0226686000823975, -0.4325127899646759, -0.2870161831378937, -0.12348837405443192, -0.33535999059677124, 1.036729097366333, 0.1056445837020874], [0.3613823354244232, 0.20851650834083557, 0.10268020629882812, -0.5401704907417297, -0.20404848456382751, -0.5413349866867065, -0.6137734651565552, 0.36509108543395996, 0.46239104866981506, -0.29573532938957214, -0.4568139314651489, 0.14603692293167114, -0.1900632381439209, 0.46691274642944336, -0.43053674697875977, -0.06848406791687012], [0.2579193711280823, -0.19391152262687683, 0.3724598288536072, -0.9880755543708801, -0.5024209022521973, -0.8012173175811768, -0.7522848844528198, 0.6977262496948242, 0.13938571512699127, 0.10503871738910675, -0.4233185052871704, 0.07679695636034012, -0.04518592730164528, 0.9119148254394531, 0.2650412321090698, -0.2545698583126068], [0.46719464659690857, 0.042420893907547, -0.3951643407344818, -0.1814221888780594, 0.035020411014556885, -0.10962232947349548, -0.6606118679046631, 0.529033362865448, 0.31473103165626526, -0.05096712335944176, -0.40098005533218384, 0.3449050188064575, -0.24650683999061584, 0.0663527250289917, -0.6428065299987793, 0.09088921546936035], [0.6979531645774841, 0.9907378554344177, 0.026036009192466736, 0.34328168630599976, 0.5022181868553162, -0.15075844526290894, -0.9126361608505249, 0.7783427834510803, 0.3355329632759094, -0.3123902678489685, 0.05030812323093414, 0.1802671104669571, -0.7356868982315063, -0.5008301734924316, -1.038500428199768, -0.6018134355545044], [-0.47522109746932983, -0.22112250328063965, -0.10224077850580215, -0.1744999885559082, 0.026270024478435516, -0.4552285373210907, -0.2950277030467987, 0.535840630531311, -0.3668150007724762, 0.33448725938796997, -0.04733601212501526, -0.20081272721290588, -0.34786558151245117, -0.4777626097202301, -0.018488526344299316, 0.13717781007289886], [0.2579193711280823, -0.19391150772571564, 0.3724598288536072, -0.9880755543708801, -0.5024209022521973, -0.8012173175811768, -0.7522848844528198, 0.6977262496948242, 0.13938570022583008, 0.10503870248794556, -0.4233185052871704, 0.07679695636034012, -0.04518592730164528, 0.9119148254394531, 0.26504120230674744, -0.2545698583126068], [0.2579193711280823, -0.19391150772571564, 0.3724598288536072, -0.9880755543708801, -0.5024209022521973, -0.8012173175811768, -0.7522848844528198, 0.6977262496948242, 0.13938573002815247, 0.10503871738910675, -0.4233185052871704, 0.07679695636034012, -0.04518592357635498, 0.9119148254394531, 0.2650412321090698, -0.2545698583126068], [-0.1788628101348877, -0.2890324592590332, 0.10606543719768524, -0.4259195923805237, -0.23422539234161377, -0.13759952783584595, -0.3848230540752411, 0.47326934337615967, 0.2251330465078354, 0.5549461245536804, -0.6531463265419006, -0.10807207226753235, 0.11729617416858673, 0.22708982229232788, 0.4255715310573578, 0.07207545638084412], [0.2579193711280823, -0.19391150772571564, 0.3724598288536072, -0.9880755543708801, -0.5024209022521973, -0.8012173175811768, -0.7522848844528198, 0.6977262496948242, 0.13938570022583008, 0.10503871738910675, -0.4233185052871704, 0.07679695636034012, -0.04518592730164528, 0.9119148254394531, 0.2650412321090698, -0.2545698583126068]], [[0.6979531645774841, 0.9907379150390625, 0.02603602409362793, 0.34328168630599976, 0.5022181868553162, -0.15075844526290894, -0.9126361608505249, 0.7783427834510803, 0.33553293347358704, -0.3123902678489685, 0.05030810832977295, 0.1802670955657959, -0.7356868982315063, -0.5008301734924316, -1.038500428199768, -0.6018134355545044], [0.6979531645774841, 0.9907378554344177, 0.02603602409362793, 0.34328168630599976, 0.5022181868553162, -0.15075844526290894, -0.9126361608505249, 0.7783427834510803, 0.33553293347358704, -0.3123902678489685, 0.05030810832977295, 0.1802671104669571, -0.7356868982315063, -0.5008301734924316, -1.038500428199768, -0.6018134355545044], [0.6979531645774841, 0.9907378554344177, 0.02603602409362793, 0.34328168630599976, 0.5022181868553162, -0.15075844526290894, -0.9126361608505249, 0.7783427834510803, 0.33553293347358704, -0.3123902678489685, 0.05030813813209534, 0.1802670955657959, -0.7356868982315063, -0.5008301734924316, -1.038500428199768, -0.6018134355545044], [0.6979531645774841, 0.9907378554344177, 0.026036009192466736, 0.34328168630599976, 0.5022181868553162, -0.15075844526290894, -0.9126361608505249, 0.7783427834510803, 0.33553293347358704, -0.3123902678489685, 0.05030812323093414, 0.1802671104669571, -0.7356868982315063, -0.5008301734924316, -1.038500428199768, -0.6018134355545044], [0.5064933896064758, -0.386511892080307, -1.0274425745010376, 0.7942101359367371, 0.5001444816589355, 0.9616584181785583, 0.550369381904602, -0.01453845202922821, -0.045306384563446045, 0.42842599749565125, 0.5312129259109497, 0.4640740752220154, 0.3081885576248169, 0.15600991249084473, 0.5855861902236938, 0.1759287714958191], [0.3325748145580292, 0.31554800271987915, -0.3245593309402466, 0.4659247398376465, 0.3049769699573517, 0.13852816820144653, 0.3283149302005768, 0.39458000659942627, 0.2089461386203766, -0.09594699740409851, 0.5215978622436523, 0.10487103462219238, 0.11901634931564331, 0.2082216888666153, -0.15143656730651855, -0.43582016229629517], [0.5064933896064758, -0.3865119218826294, -1.0274425745010376, 0.7942101359367371, 0.5001444816589355, 0.9616583585739136, 0.550369381904602, -0.01453845202922821, -0.04530637711286545, 0.42842599749565125, 0.5312129259109497, 0.4640740752220154, 0.3081885576248169, 0.15600991249084473, 0.5855861902236938, 0.17592878639698029], [0.5064933896064758, -0.386511892080307, -1.0274425745010376, 0.7942101359367371, 0.5001444816589355, 0.9616584181785583, 0.550369381904602, -0.01453845202922821, -0.04530637711286545, 0.42842599749565125, 0.5312129259109497, 0.4640740752220154, 0.3081885576248169, 0.15600988268852234, 0.5855861902236938, 0.17592878639698029], [0.3325748145580292, 0.31554797291755676, -0.3245593011379242, 0.4659247398376465, 0.3049769699573517, 0.13852816820144653, 0.3283149302005768, 0.39458000659942627, 0.2089461237192154, -0.09594700485467911, 0.5215978622436523, 0.10487103462219238, 0.11901634931564331, 0.2082216888666153, -0.15143656730651855, -0.43582016229629517], [0.3325748145580292, 0.31554797291755676, -0.3245593309402466, 0.46592476963996887, 0.3049769699573517, 0.13852816820144653, 0.32831496000289917, 0.39458000659942627, 0.2089461237192154, -0.0959470272064209, 0.5215978622436523, 0.10487103462219238, 0.11901631951332092, 0.2082216739654541, -0.15143656730651855, -0.43582016229629517], [0.3325748145580292, 0.31554797291755676, -0.3245592713356018, 0.46592476963996887, 0.3049769699573517, 0.13852816820144653, 0.3283149302005768, 0.39458000659942627, 0.2089461237192154, -0.0959470123052597, 0.5215978622436523, 0.10487103462219238, 0.11901634931564331, 0.2082216739654541, -0.15143656730651855, -0.43582016229629517], [0.5064933896064758, -0.386511892080307, -1.0274425745010376, 0.7942101359367371, 0.5001444816589355, 0.9616584181785583, 0.550369381904602, -0.014538437128067017, -0.045306384563446045, 0.42842599749565125, 0.5312129259109497, 0.4640740752220154, 0.3081885576248169, 0.15600989758968353, 0.5855861902236938, 0.1759287714958191], [0.5837769508361816, 0.9275041222572327, -0.8443831205368042, 0.12804903090000153, 0.544491708278656, 0.47403937578201294, 0.4794270992279053, 0.7203253507614136, -0.2125876247882843, -0.948099672794342, 0.04304513335227966, 0.7359297275543213, -0.10008683800697327, 0.19604992866516113, -0.7143048644065857, 0.6421520709991455], [0.5837769508361816, 0.9275041222572327, -0.8443831205368042, 0.12804903090000153, 0.544491708278656, 0.47403937578201294, 0.4794270992279053, 0.7203253507614136, -0.2125876247882843, -0.948099672794342, 0.04304513335227966, 0.7359297275543213, -0.10008683800697327, 0.19604992866516113, -0.7143048644065857, 0.6421520709991455], [0.5837769508361816, 0.9275041222572327, -0.8443831205368042, 0.12804904580116272, 0.544491708278656, 0.47403937578201294, 0.4794270992279053, 0.7203253507614136, -0.2125876247882843, -0.948099672794342, 0.04304513335227966, 0.7359297275543213, -0.10008683800697327, 0.19604992866516113, -0.7143048644065857, 0.6421520709991455], [0.5837769508361816, 0.9275041222572327, -0.8443831205368042, 0.12804903090000153, 0.544491708278656, 0.47403937578201294, 0.4794270992279053, 0.7203253507614136, -0.2125876247882843, -0.948099672794342, 0.04304513335227966, 0.7359297275543213, -0.10008683800697327, 0.19604989886283875, -0.7143048644065857, 0.6421520709991455]], [[-0.1788628101348877, -0.2890324294567108, 0.10606542229652405, -0.4259195923805237, -0.23422540724277496, -0.13759954273700714, -0.3848230540752411, 0.47326934337615967, 0.22513306140899658, 0.5549461245536804, -0.6531463265419006, -0.10807208716869354, 0.11729617416858673, 0.22708982229232788, 0.4255715310573578, 0.07207547128200531], [0.3613823354244232, 0.20851649343967438, 0.10268021374940872, -0.5401704907417297, -0.20404848456382751, -0.5413349866867065, -0.6137734651565552, 0.36509108543395996, 0.46239104866981506, -0.29573532938957214, -0.4568139314651489, 0.14603693783283234, -0.1900632381439209, 0.46691274642944336, -0.43053674697875977, -0.06848405301570892], [-0.38442307710647583, 0.4865400195121765, 0.6580949425697327, -0.14802426099777222, -0.10401082038879395, -0.5258643627166748, -0.6871569752693176, 0.804716169834137, 0.1375178098678589, 0.27511703968048096, -0.39235571026802063, -0.35199618339538574, -0.43947771191596985, -0.11364033818244934, 0.07894593477249146, -0.5208229422569275], [-0.8596593141555786, -0.31278008222579956, -0.16309493780136108, 1.0228842496871948, 0.3500315546989441, 0.9652230739593506, -0.28755995631217957, 0.11585289239883423, -0.2446747124195099, -0.1263284981250763, -0.29036739468574524, -0.8915265798568726, -0.38076433539390564, -0.9897648692131042, 1.01041579246521, -0.23573949933052063], [-0.1788628101348877, -0.2890324294567108, 0.10606542974710464, -0.4259195923805237, -0.23422540724277496, -0.13759954273700714, -0.3848230540752411, 0.47326934337615967, 0.22513306140899658, 0.5549461245536804, -0.6531463265419006, -0.10807207226753235, 0.11729617416858673, 0.22708982229232788, 0.4255715310573578, 0.07207547128200531], [0.5815469622612, 0.8193275332450867, -0.04367157816886902, -0.23612618446350098, 0.1987346112728119, -0.370801717042923, -0.4949207007884979, 0.6815537214279175, 0.5220808386802673, -0.5869254469871521, -0.22457373142242432, 0.16372837126255035, -0.21941831707954407, 0.2997949421405792, -0.6521328687667847, -0.18093407154083252], [0.46719464659690857, 0.042420893907547, -0.3951643407344818, -0.1814221888780594, 0.03502039611339569, -0.10962232947349548, -0.6606118679046631, 0.529033362865448, 0.31473103165626526, -0.05096709728240967, -0.40098005533218384, 0.3449050188064575, -0.24650683999061584, 0.06635275483131409, -0.6428065299987793, 0.09088921546936035], [0.2579193711280823, -0.19391150772571564, 0.3724598288536072, -0.9880755543708801, -0.5024209022521973, -0.8012173175811768, -0.7522848844528198, 0.6977262496948242, 0.13938571512699127, 0.10503870248794556, -0.4233185052871704, 0.07679695636034012, -0.04518592357635498, 0.9119148254394531, 0.2650412321090698, -0.2545698583126068], [-0.009599536657333374, 0.07957786321640015, -0.5278271436691284, -0.16804951429367065, 0.2429427057504654, -0.06411717087030411, -0.17453938722610474, 0.77238929271698, -0.15387719869613647, -0.049077801406383514, -0.42700380086898804, 0.2612093687057495, -0.2767356038093567, -0.23993991315364838, -0.4380418062210083, 0.5309122204780579], [-0.38442307710647583, 0.4865400195121765, 0.6580949425697327, -0.14802426099777222, -0.10401082038879395, -0.5258643627166748, -0.6871569752693176, 0.804716169834137, 0.13751782476902008, 0.27511703968048096, -0.39235571026802063, -0.35199618339538574, -0.43947771191596985, -0.11364034563302994, 0.07894593477249146, -0.5208229422569275], [0.8988809585571289, -0.3904299736022949, 0.3343751132488251, 0.09324085712432861, 0.3227062225341797, 0.39892685413360596, -0.17363286018371582, 0.3418302536010742, 0.7256202101707458, 1.3308838605880737, 0.3704042434692383, -0.1688811480998993, 0.1632632315158844, -0.2779444754123688, 0.355768084526062, -0.9400664567947388], [0.39655801653862, -0.3775057792663574, -0.9366081953048706, 0.35290291905403137, 0.2778562605381012, 0.551339864730835, -0.27904531359672546, 0.43349689245224, 0.01460091769695282, 0.36009544134140015, -0.22552496194839478, 0.3915311098098755, -0.18493102490901947, -0.43700098991394043, -0.39858126640319824, 0.42025721073150635], [-0.38442304730415344, 0.4865400195121765, 0.6580949425697327, -0.14802426099777222, -0.10401082038879395, -0.5258643627166748, -0.6871569752693176, 0.804716169834137, 0.13751782476902008, 0.27511703968048096, -0.39235571026802063, -0.35199618339538574, -0.43947771191596985, -0.11364033818244934, 0.07894593477249146, -0.5208229422569275], [0.24611496925354004, 0.7385416030883789, -0.12760323286056519, 0.6942645907402039, 0.5720617175102234, 0.488954097032547, -0.3304724395275116, 0.4875778555870056, 0.34482541680336, 0.2579336166381836, -0.16063934564590454, -0.178459033370018, -0.25224414467811584, -0.6884581446647644, -0.39547601342201233, -0.26416659355163574], [0.2579193711280823, -0.19391152262687683, 0.3724598288536072, -0.9880755543708801, -0.5024209022521973, -0.8012173175811768, -0.7522848844528198, 0.6977262496948242, 0.13938570022583008, 0.10503871738910675, -0.4233185052871704, 0.07679694890975952, -0.04518592357635498, 0.9119148254394531, 0.2650412321090698, -0.2545698583126068], [0.25791940093040466, -0.19391150772571564, 0.3724598288536072, -0.9880755543708801, -0.5024209022521973, -0.8012173175811768, -0.7522848844528198, 0.6977262496948242, 0.13938571512699127, 0.10503872483968735, -0.4233185052871704, 0.07679695636034012, -0.04518592357635498, 0.9119148254394531, 0.2650412321090698, -0.2545698583126068]]]\n",
            "16\n",
            "(64, 16)\n"
          ]
        }
      ],
      "source": [
        "init_population=np.array(vq_layer_x)\n",
        "init_population_list=[]\n",
        "\n",
        "for i in range(len(init_population)):\n",
        "  init_population_list.append(init_population[i].reshape(-1, 16).tolist())\n",
        "\n",
        "print(init_population[0].shape)\n",
        "\n",
        "print(init_population_list[:3])\n",
        "print(len(init_population_list[0][0]))\n",
        "\n",
        "## create the codebook a[:][i]\n",
        "a = a.T\n",
        "\n",
        "print(a.shape)\n",
        "\n",
        "if a.shape == (64,16):\n",
        "  for i in init_population_list:\n",
        "    for j in i:\n",
        "      if j not in a:\n",
        "        print(j)\n",
        "        print(len(j))\n",
        "        print(a[0])\n",
        "        print(a[0].shape)\n",
        "else:\n",
        "  print(\"run again\")\n",
        "\n",
        "#QUESTIONS\n",
        "## HOW CODEBOOK WAS GENERATED IN COLUMN MANNER?\n",
        "## WHAT IS CODEBOOK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mael56EmKLYl"
      },
      "source": [
        "###Genetic algorithm part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UP7em1UKP_4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#import Data_Pipeline_Test as dpt\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "from PIL import Image #Need to import this to do image editing\n",
        "\n",
        "\n",
        "#### Visualizer\n",
        "def pad(array, shape):\n",
        "    print(array.shape, shape)\n",
        "    board = np.zeros(shape)\n",
        "    # area = [0: array.shape[0],0: array.shape[1],0: array.shape[2]]\n",
        "    board[0: array.shape[0],0: array.shape[1],0: array.shape[2]] = array\n",
        "    return board\n",
        "\n",
        "char_2_tile_path = {\n",
        "         \"X\": '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/X.png',\n",
        "        \"S\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/S.png',\n",
        "        \"-\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/-.png',\n",
        "        \"?\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/Q.png',\n",
        "        \"Q\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/Q.png',\n",
        "        \"E\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/E.png',\n",
        "        \"<\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/PTL.png',\n",
        "        \">\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/PTR.png',\n",
        "        \"[\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/[.png',\n",
        "        \"]\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/].png',\n",
        "        \"o\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/o.png',\n",
        "        \"B\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/0.png',\n",
        "        \"b\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/0.png',\n",
        "        \"#\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/#.png',\n",
        "        \"D\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/D.png',\n",
        "        \"H\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/H.png',\n",
        "        \"M\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/M.png',\n",
        "        \"T\" : '/Users/mohammadrezahami/Documents/University/PCG/Project/Code/sprites/T.png',\n",
        "        }\n",
        "\n",
        "def get_tiles():\n",
        "  char_2_tile = {}\n",
        "  for char, path in char_2_tile_path.items():\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    char_2_tile[char] = pad(img, shape=(16,16,3))\n",
        "\n",
        "  return char_2_tile\n",
        "\n",
        "char_2_tile = get_tiles()\n",
        "\n",
        "\n",
        "def visualize_ga(chunk):\n",
        "  img = np.zeros(shape=(14 * 16, 16 * 16, 3))\n",
        "\n",
        "  row_idx = 0\n",
        "  col_idx = 0\n",
        "\n",
        "  for row in chunk:\n",
        "    for char in row:\n",
        "      img[row_idx:row_idx+16, col_idx:col_idx+16, :] = char_2_tile[char]\n",
        "      col_idx += 16\n",
        "    row_idx += 16\n",
        "    col_idx = 0\n",
        "\n",
        "  return img\n",
        "\n",
        "\n",
        "def visualize(individual):\n",
        "\n",
        "    #Load the set of all sprites\n",
        "    sprites = {}\n",
        "    for filename in glob.glob(os.path.join(os.getcwd(), \"sprites\", \"*.png\")):\n",
        "        im = Image.open(filename)\n",
        "        splits = filename.split(\"/\")\n",
        "        name = splits[-1][:-4]\n",
        "        sprites[name] = im.convert('RGBA')\n",
        "\n",
        "    #This gives the mapping between the tile values and the associated sprite\n",
        "    visualization = {}\n",
        "    visualization[\"X\"] = \"X1\"\n",
        "    visualization[\"S\"] = \"S\"\n",
        "    visualization[\"-\"] = \"-\"\n",
        "    visualization[\"?\"] = \"Q\"\n",
        "    visualization[\"Q\"] = \"Q\"\n",
        "    visualization[\"E\"] = \"E\"\n",
        "    visualization[\"<\"] = \"PTL\"\n",
        "    visualization[\">\"] = \"PTR\"\n",
        "    visualization[\"[\"] = \"pipe\"\n",
        "    visualization[\"]\"] = \"pipe_r\"\n",
        "    visualization[\"o\"] = \"o\"\n",
        "    #visulization[\"B\"] = \"\"\n",
        "    #visulization[\"b\"] =\n",
        "    visualization[\"T\"] = \"T\"\n",
        "    visualization[\"M\"] = \"M\"\n",
        "    visualization[\"D\"] = \"D\"\n",
        "    visualization[\"#\"] = \"X\"\n",
        "    visualization[\"H\"] = \"H\"\n",
        "\n",
        "    # This reads in the level\n",
        "    # level = {}\n",
        "    # with open(os.path.join(os.getcwd(), \"Generated Levels\", \"output.txt\")) as fp:\n",
        "    #     y = 0\n",
        "    #     for line in fp:\n",
        "    #         level[y] = line\n",
        "    #         y+=1\n",
        "\n",
        "    #Multiply by 18 here as each of the sprites is 14*16\n",
        "    image = Image.new(\"RGB\", (14*len(individual[0]), 16*len(individual)), color=(223, 245, 244)) #This creates an initially blank image for the level\n",
        "    pixels = image.load() #This loads the level image's pixels so we can edit them\n",
        "\n",
        "    maxY = len(individual)\n",
        "    maxX = len(individual[0])\n",
        "\n",
        "    for y in range(0, maxY):\n",
        "        for x in range(0, maxX):\n",
        "            imageToUse = None\n",
        "            if individual[y][x] in visualization.keys():\n",
        "                imageToUse = sprites[visualization[individual[y][x]]]\n",
        "                #print(imageToUse)\n",
        "            #elif individual[y][x]==\"X\":\n",
        "                #Rules we've added to ensure the correct sprite is used\n",
        "                #if y==maxY-2:\n",
        "                   # imageToUse = sprites[\"groundTop\"]\n",
        "                # elif y==maxY-1:\n",
        "                #     #Check if we have a solid tile above this and change which sprite we use if so\n",
        "                #     if individual[y-1][x]==\"X\":\n",
        "                #         imageToUse = sprites[\"groundBottom\"]\n",
        "                #     else:\n",
        "                #         imageToUse = sprites[\"groundTop\"]\n",
        "                # else:\n",
        "                #     imageToUse = sprites[\"stair\"]\n",
        "\n",
        "            if not imageToUse == None:\n",
        "                #If we have a sprite (imageToUse) copy its pixels over\n",
        "                pixelsToUse = imageToUse.load()\n",
        "                for x2 in range(0, 13):\n",
        "                    for y2 in range(0, 15):\n",
        "                        if pixelsToUse[x2,y2][3]>0:\n",
        "                            pixels[x*14+x2,y*16+y2] = pixelsToUse[x2,y2][0:-1]\n",
        "    return image\n",
        "\n",
        "\n",
        "def mutation(individual, mutation_rate):\n",
        "    if np.random.random()<mutation_rate:\n",
        "\n",
        "        ###attempt1\n",
        "        ## change one cell to soomething random between 1 and 16\n",
        "        row = np.random.randint(0,len(individual))\n",
        "        column = np.random.randint(0,len(individual[0]))\n",
        "        smb_elements = ['S','?','Q','E','<','>','[',']','o','B','b']\n",
        "        kl_elements = ['T','M','D','H']\n",
        "        elements = smb_elements + kl_elements\n",
        "        individual[row][column] = elements[np.random.randint(0,15)]\n",
        "        return individual\n",
        "\n",
        "        ###attempt2\n",
        "        ## swap 2 cells of the individual\n",
        "        # row_1 = np.random.randint(0,len(individual))\n",
        "        # column_1 = np.random.randint(0,len(individual[0]))\n",
        "\n",
        "        # row_2 = np.random.randint(0,len(individual))\n",
        "        # column_2 = np.random.randint(0,len(individual[0]))\n",
        "\n",
        "        # while not (row_1==row_2 and column_1==column_2):\n",
        "        #     row_2 = np.random.randint(0,len(individual))\n",
        "        #     column_2 = np.random.randint(0,len(individual[0]))\n",
        "        # tmp = individual[row_1][column_1]\n",
        "        # individual[row_1][column_1] = individual[row_2][column_2]\n",
        "        # individual[row_2][column_2] = tmp\n",
        "        # return individual\n",
        "    else:\n",
        "        return individual\n",
        "\n",
        "def crossover(individual_1, individual_2, crossover_rate):\n",
        "    child_1 = np.array([[]]).reshape(0,16)\n",
        "    child_2 = np.array([[]]).reshape(0,16)\n",
        "    if np.random.random()<crossover_rate:\n",
        "\n",
        "        # if np.random.randint(0,2):\n",
        "        if 0:\n",
        "            ##crossover by row\n",
        "\n",
        "            rand_row_cut = np.random.randint(0, 13)\n",
        "            child_1 = np.concatenate((child_1,individual_1[:rand_row_cut+1]))\n",
        "            #child_1 = individual_1[:rand_row_cut+1]\n",
        "            child_1 = np.concatenate((child_1,individual_2[rand_row_cut+1:]))\n",
        "            #child_1 += individual_2[rand_row_cut+1:]\n",
        "\n",
        "\n",
        "            child_2 = np.concatenate((child_2,individual_1[rand_row_cut+1:]))\n",
        "            #child_2 = individual_1[rand_row_cut+1:]\n",
        "            child_2 = np.concatenate((child_2,individual_2[:rand_row_cut+1]))\n",
        "            #child_2 += individual_2[:rand_row_cut+1]\n",
        "\n",
        "            return child_1, child_2\n",
        "\n",
        "        else:\n",
        "            ##crossover by column\n",
        "            rand_cul_cut = np.random.randint(0, 14)\n",
        "            for row in range(len(individual_1)):\n",
        "                temp1 = np.array([[]]).reshape(0,16)\n",
        "                temp1 = np.concatenate((individual_1[row][:rand_cul_cut+1],individual_2[row][rand_cul_cut+1:]))\n",
        "                #child_1=individual_1[row][:rand_cul_cut+1]\n",
        "                temp1 = np.array([temp1])\n",
        "                child_1 = np.concatenate((child_1,temp1))\n",
        "                #child_1[row] += individual_2[row][rand_cul_cut+1:]\n",
        "\n",
        "                temp2 = np.array([[]]).reshape(0,16)\n",
        "                temp2 = np.concatenate((individual_1[row][rand_cul_cut+1:],individual_2[row][:rand_cul_cut+1]))\n",
        "                #child_2.append(individual_1[row][rand_cul_cut+1:])\n",
        "                #child_2[row] += individual_2[row][:rand_cul_cut+1]\n",
        "                temp2 = np.array([temp2])\n",
        "                child_2 = np.concatenate((child_2,temp2))\n",
        "\n",
        "            return child_1, child_2\n",
        "    else:\n",
        "        return child_1, child_2\n",
        "\n",
        "def evolution(population, population_limit,passable_point,passable_smb_sum,passable_kid_sum, solid_point, solid_smb_sum, solid_kid_sum):\n",
        "    newpopulation = []\n",
        "    fitness_population = []\n",
        "    for individual in population:\n",
        "        fitness_population.append((fitness(individual, passable_point,passable_smb_sum,passable_kid_sum, solid_point, solid_smb_sum, solid_kid_sum), individual))\n",
        "\n",
        "    # np.sort(fitness_population,axis=0)\n",
        "\n",
        "    fitness_population.sort(key=lambda tup: tup[0], reverse=True)\n",
        "    for i in range(population_limit//5*4):\n",
        "        newpopulation.append(fitness_population[i][1])\n",
        "\n",
        "    ## also append some random trash\n",
        "    inthelist = []\n",
        "    for i in range(population_limit//5):\n",
        "        rand_individual = np.random.randint(len(population)//5*4,len(population))\n",
        "\n",
        "\n",
        "        while rand_individual in inthelist:\n",
        "            rand_individual = np.random.randint(len(population)//5*4,len(population))\n",
        "\n",
        "        newpopulation.append(fitness_population[rand_individual][1])\n",
        "        inthelist.append(rand_individual)\n",
        "\n",
        "    return newpopulation\n",
        "\n",
        "def fitness(individual, passable_point,passable_smb_sum,passable_kid_sum, solid_point, solid_smb_sum, solid_kid_sum):\n",
        "    distribution = {}\n",
        "    smb_elements = ['X','S','-','?','Q','E','<','>','[',']','o','B','b']\n",
        "    kl_elements = ['T','M','D','#','H','-']\n",
        "    elements = smb_elements + kl_elements\n",
        "    distribution = dpt.distribution_extractor(individual, elements, distribution)\n",
        "\n",
        "\n",
        "    passable = ['o','-','M','T']\n",
        "    solid = ['X','S','?','Q', '#','H']\n",
        "    passable_sum = 0\n",
        "    solid_sum = 0\n",
        "\n",
        "    for key in distribution:\n",
        "        if key in passable:\n",
        "            passable_sum += distribution[key]\n",
        "        elif key in solid:\n",
        "            solid_sum += distribution[key]\n",
        "\n",
        "    #print(\"solid\",solid_sum)\n",
        "\n",
        "    #for passable\n",
        "    fitness_passable = 0\n",
        "    if passable_smb_sum <= passable_kid_sum:\n",
        "        if passable_sum >= passable_smb_sum and passable_sum <= passable_point:\n",
        "            fitness_passable = ((passable_point - passable_sum) / (passable_smb_sum - passable_point)) + 1\n",
        "\n",
        "        elif passable_sum <= passable_kid_sum and passable_sum >= passable_point:\n",
        "            fitness_passable = ((passable_point - passable_sum) / (passable_kid_sum - passable_point)) + 1\n",
        "        else:\n",
        "            fitness_passable = 0\n",
        "    else:\n",
        "        if passable_sum >= passable_kid_sum and passable_sum <= passable_point:\n",
        "            fitness_passable = ((passable_point - passable_sum) / (passable_kid_sum - passable_point)) + 1\n",
        "\n",
        "        elif passable_sum <= passable_smb_sum and passable_sum >= passable_point:\n",
        "            fitness_passable = ((passable_point - passable_sum) / (passable_smb_sum - passable_point)) + 1\n",
        "        else:\n",
        "            fitness_passable = 0\n",
        "\n",
        "\n",
        "    # print(\"passable_sum:\",passable_sum)\n",
        "    # print(\"passable_smb:\",passable_smb_sum)\n",
        "    # print(\"passable_kid:\",passable_kid_sum)\n",
        "    # print(\"passable_point:\",passable_point)\n",
        "    # print(\"passable_fitness:\",fitness_passable)\n",
        "\n",
        "    #for solid\n",
        "    fitness_solid = 0\n",
        "    if solid_smb_sum <= solid_kid_sum:\n",
        "        if solid_sum >= solid_smb_sum and solid_sum <= solid_point:\n",
        "            fitness_solid = ((solid_point - solid_sum) / (solid_smb_sum - solid_point)) + 1\n",
        "\n",
        "        elif solid_sum <= solid_kid_sum and solid_sum >= solid_point:\n",
        "            fitness_solid = ((solid_point - solid_sum) / (solid_kid_sum - solid_point)) + 1\n",
        "        else:\n",
        "            fitness_solid = 0\n",
        "    else:\n",
        "        if solid_sum >= solid_kid_sum and solid_sum <= solid_point:\n",
        "            fitness_solid = ((solid_point - solid_sum) / (solid_kid_sum - solid_point)) + 1\n",
        "\n",
        "        elif solid_sum <= solid_smb_sum and solid_sum >= solid_point:\n",
        "            fitness_solid = ((solid_point - solid_sum) / (solid_smb_sum - solid_point)) + 1\n",
        "        else:\n",
        "            fitness_solid = 0\n",
        "\n",
        "    fitness= (fitness_passable + fitness_solid)/2\n",
        "\n",
        "    return fitness\n",
        "\n",
        "def generation(population:list, crossover_rate, mutation_rate, population_limit, passable_point,passable_smb_sum,passable_kid_sum, solid_point, solid_smb_sum, solid_kid_sum):\n",
        "    ##select parents\n",
        "    for _ in range(len(population)//3):\n",
        "        parent_1 = np.random.randint(0,len(population))\n",
        "        parent_2 = np.random.randint(0,len(population))\n",
        "        while parent_1 == parent_2:\n",
        "            parent_2 = np.random.randint(0,len(population))\n",
        "        child_1, child_2 = crossover(population[parent_1], population[parent_2], crossover_rate)\n",
        "        ##do crossover\n",
        "        if child_1.size != 0 and child_2.size != 0:\n",
        "            population.append(child_1)\n",
        "            population.append(child_2)\n",
        "\n",
        "    ##do mutation\n",
        "    for individual in population:\n",
        "        individual = mutation(individual, mutation_rate)\n",
        "\n",
        "    ##do evolution\n",
        "    population = evolution(population, population_limit, passable_point,passable_smb_sum,passable_kid_sum, solid_point, solid_smb_sum, solid_kid_sum)\n",
        "\n",
        "    return population\n",
        "\n",
        "\n",
        "def main():\n",
        "    num_generation = 500\n",
        "    population = []\n",
        "    crossover_rate = 0.8\n",
        "    mutation_rate = 0.05\n",
        "    population_limit = 250\n",
        "    blending_point = 0.33\n",
        "    mario_address = 'mario-3-3.txt'\n",
        "    kidicarus_address = 'kidicarus_1.txt'\n",
        "    passable_point,passable_smb_sum,passable_kid_sum, solid_point, solid_smb_sum, solid_kid_sum = dpt.points_extractor(mario_address, kidicarus_address,blending_point)\n",
        "\n",
        "    dataset_smb, dataset_kid = dpt.dataset_creator(mario_address,kidicarus_address)\n",
        "\n",
        "    population = dataset_kid + dataset_smb\n",
        "\n",
        "    for epoch in range(num_generation):\n",
        "        print(\"-----\",epoch,\"-----\")\n",
        "        population = generation(population, crossover_rate, mutation_rate, population_limit, passable_point, passable_smb_sum, passable_kid_sum, solid_point, solid_smb_sum, solid_kid_sum)\n",
        "\n",
        "    fitness_population = []\n",
        "    for individual in population:\n",
        "        fitness_population.append((fitness(individual, passable_point,passable_smb_sum,passable_kid_sum, solid_point, solid_smb_sum, solid_kid_sum), individual))\n",
        "\n",
        "    fitness_population.sort(key=lambda tup: tup[0], reverse=True)\n",
        "\n",
        "    i = 0\n",
        "    for individual in fitness_population[:50]:\n",
        "        #print(individual[1],individual[0])\n",
        "        #print(\"------------------------------------------\")\n",
        "        #print(\"------------------------------------------\")\n",
        "        image = visualize_ga(individual[1])\n",
        "        cv2.imwrite(\"output\"+str(i)+'.png',image)\n",
        "        # image.save(\"./outputs/output\"+str(i)+\".jpeg\",\"JPEG\")\n",
        "        i += 1\n",
        "        print(\"output \",str(i),\": \",individual[0])\n",
        "\n",
        "if __name__ == main():\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynJNKSRU5XTy"
      },
      "source": [
        "###### non GA Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_Pf-NA9yE9n"
      },
      "outputs": [],
      "source": [
        "#raw_data = np.concatenate([smb_data, ki_data])\n",
        "#np.random.shuffle(raw_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEcA4_bpsQKg",
        "outputId": "f826e192-0208-442d-e2f5-290f0db40558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "120/120 [==============================] - 7s 50ms/step - loss: 0.7361 - reconstruction_loss: 0.3795 - vqvae_loss: 0.1905\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 6s 50ms/step - loss: 0.3495 - reconstruction_loss: 0.2469 - vqvae_loss: 0.0969\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 6s 50ms/step - loss: 0.4638 - reconstruction_loss: 0.2218 - vqvae_loss: 0.2388\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 6s 49ms/step - loss: 0.4570 - reconstruction_loss: 0.2045 - vqvae_loss: 0.2473\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 6s 49ms/step - loss: 0.3406 - reconstruction_loss: 0.1911 - vqvae_loss: 0.1452\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "vqvae_trainer = VQVAETrainer(data_variance, latent_dim=16, num_embeddings=64)\n",
        "vqvae_trainer.compile(optimizer=keras.optimizers.Adam())\n",
        "vqvae_trainer.fit(x_train, epochs=5, batch_size=32) ## 50 , 32\n",
        "\n",
        "\n",
        "\n",
        "#vq_layer = vqvae_trainer.vqvae.layers[2]\n",
        "#emb1=vq_layer.embeddings\n",
        "\n",
        "vqvae_trainer.vqvae.save_weights('model2.h5')\n",
        "\n",
        "\n",
        "vq_layer = vqvae_trainer.vqvae.layers[2]\n",
        "emb1=vq_layer.embeddings\n",
        "\n",
        "# print(type(emb1))\n",
        "a = np.array(emb1)\n",
        "\n",
        "np.save('codebook2',a)\n",
        "\n",
        "# with open(\"codebook1.txt\", 'w') as file:\n",
        "  # pickle.dump(emb1, file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE7P6PBAb_4Z",
        "outputId": "c2d7bf63-1ccc-40b8-b6d6-d97167cbced5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c = np.load('codebook.npy')\n",
        "\n",
        "\n",
        "model = get_vqvae(latent_dim=16, num_embeddings=64)\n",
        "model.load_weights('model.h5')\n",
        "\n",
        "vq_layer = model.layers[2]\n",
        "emb1=vq_layer.embeddings\n",
        "emb1=np.array(emb1)\n",
        "\n",
        "\n",
        "c2 = np.load('codebook2.npy')\n",
        "\n",
        "model2 = get_vqvae(latent_dim=16, num_embeddings=64)\n",
        "model2.load_weights('model2.h5')\n",
        "\n",
        "vq_layer2 = model2.layers[2]\n",
        "emb2=vq_layer2.embeddings\n",
        "emb2=np.array(emb2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "emb1==emb2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXFNRwiijD7c"
      },
      "outputs": [],
      "source": [
        "trained_vqvae_model = vqvae_trainer.vqvae\n",
        "\n",
        "# idx = np.random.choice(len(x_test), 2)\n",
        "\n",
        "# inpt = x_test[idx]\n",
        "inpt = x_test[[2796, 139]]\n",
        "\n",
        "input_layer = vqvae_trainer.vqvae.layers[0]\n",
        "encoder_layer = vqvae_trainer.vqvae.layers[1]\n",
        "vq_layer = vqvae_trainer.vqvae.layers[2]\n",
        "decoder_layer = vqvae_trainer.vqvae.layers[3]\n",
        "\n",
        "\n",
        "input_layer_x = input_layer(inpt)\n",
        "encoder_layer_x = encoder_layer(input_layer_x)\n",
        "vq_layer_x = vq_layer(encoder_layer_x)\n",
        "decoder_layer_x = decoder_layer(vq_layer_x)\n",
        "\n",
        "direct_output = trained_vqvae_model.predict(inpt)\n",
        "\n",
        "\n",
        "# print('direct output\\t\\t\\t decoder output\\t\\t sample 1')\n",
        "# print(print_side_by_side(direct_output[0], decoder_layer_x[0]))\n",
        "\n",
        "# print('direct output\\t\\t\\t decoder output\\t\\t sample 2')\n",
        "# print(print_side_by_side(direct_output[1], decoder_layer_x[1]))\n",
        "\n",
        "\n",
        "xx = vq_layer_x.numpy()\n",
        "\n",
        "print(xx[0].shape)\n",
        "A = xx[0].reshape(-1, 16).tolist()\n",
        "B = xx[1].reshape(-1, 16).tolist()\n",
        "\n",
        "print(len(A))\n",
        "\n",
        "A[0] = B[0]\n",
        "\n",
        "print('MAP ID ', 2796)\n",
        "\n",
        "for i in range(len(A)):\n",
        "\n",
        "  xx_decoded = decoder_layer(np.array(A).reshape(1, 4, 4, 16))\n",
        "\n",
        "  decoded_text = chunk_2_text(xx_decoded[0])\n",
        "  print(decoded_text)\n",
        "  #img = visualize(decoded_text)\n",
        "\n",
        "  ##### img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  #cv2.imwrite('/content/drive/MyDrive/pcgml_temp/visualize/{}.png'.format(i), img)\n",
        "  print()\n",
        "  A[i] = B[i]\n",
        "xx_decoded = decoder_layer(np.array(A).reshape(1, 4, 4, 16))\n",
        "img = visualize(decoded_text)\n",
        "cv2.imwrite('/content/drive/MyDrive/pcgml_temp/visualize/{}.png'.format(i+1), img)\n",
        "print(chunk_2_text(xx_decoded[0]))\n",
        "print('MAP ID ', 139)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0k1BhkPsgpn",
        "outputId": "03598ffe-5424-4888-9d1d-918f7c829344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3187 3446  822 2601  139 1668  274 1019 1256  450]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Original\t\t\tReconstructed\n",
            "#----#TTTT--####                -------------###\n",
            "#--##TTTT--####-                -------------###\n",
            "#-########----##                #######--------#\n",
            "#-------------##                #-------------##\n",
            "#-------------D#                #-------------##\n",
            "#-------------D#                #-------------##\n",
            "#-D---------####                #------------###\n",
            "#-D-----####----                #--------###----\n",
            "TTTTTTTT--TTTTTT                #---TTTTT-------\n",
            "----------------                ----------------\n",
            "---------------#                ----------------\n",
            "-TTTTTTTT----###                TTTTTTTTT----##-\n",
            "------------####                ------------####\n",
            "----------------                ----------------\n",
            "--------TTT-----                --------TTTT----\n",
            "----------------                ----------------\n",
            "\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "-------o--------                ----------------\n",
            "------XXX-------                ------XX--------\n",
            "----------o-----                ----------------\n",
            "---o------XXXX--                ---------XXXX---\n",
            "X-XXX-----------                -XXXX-----------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "-------------XXX                --------------XX\n",
            "-E--------------                ----------------\n",
            "XXXXXXXXXX------                XXXXXXXXXXX-----\n",
            "\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "-------E--------                -------E--------\n",
            "------<>--------                ------<>--------\n",
            "------[]--------                ------[]--------\n",
            "E-EE--[]--------                ------[]--------\n",
            "XXXXXXXXXXXXXXXX                XXXXXXXXXXXXXXXX\n",
            "\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "X--X----------XX                ---X----------XX\n",
            "X--XX--------XXX                --XXX--------XXX\n",
            "X--XXX------XXXX                -XXXXX------XXXX\n",
            "X--XXXX----XXXXX                XXXXXX-----XXXXX\n",
            "XXXXXXXXXXXXXXXX                XXXXXXXXXXXXXXXX\n",
            "\n",
            "#---########--D#                ##-----#########\n",
            "##------########                ##-----#########\n",
            "##----------####                ##-----#########\n",
            "##-----------###                ##----------####\n",
            "##########---###                ######-#-----###\n",
            "####-----------#                ######--------##\n",
            "####-----------#                #####---------##\n",
            "---------####--#                ##-----#####--##\n",
            "##-------##---##                ##-------##-----\n",
            "##----#####---#-                ##-------##---##\n",
            "##------------#-                ##-#----------##\n",
            "#####---------#-                ##-#----------##\n",
            "--------------##                --------------##\n",
            "---####-------##                ----##--------##\n",
            "-----##-------##                ----##--------##\n",
            "-----#####----##                -----######---##\n",
            "\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "-------SSS------                --------SS------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "EE--------------                ----------------\n",
            "--XX-XX---------                --XXXX----------\n",
            "--XX-XX---------                -----XX---------\n",
            "--XX-XXX--------                -----XXX--------\n",
            "--X--XXX--E-E---                -----XXXX-------\n",
            "--X--XXXXXXXXXXX                ----XXXXXXXXXXXX\n",
            "\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "-----XX---------                -----XX---------\n",
            "-----XX---------                -----XX---------\n",
            "---X-XX---------                -----XX---------\n",
            "---X-XX---------                ----XXX---------\n",
            "-X-X-XX---------                XXXXXXX---------\n",
            "-X-X-XX---------                XXXXXXX---------\n",
            "-X-X-XX---------                X---XXX---------\n",
            "-X-X-XX--------X                X---XXX---------\n",
            "-X-X-XXXXXXXXXXX                ----XXXXXXXXXXXX\n",
            "\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "-----oooo-------                ------SSS-------\n",
            "------------XXXX                ------------XXXX\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "XXXXXXX-XXXX----                XXXXXXXXXXXX----\n",
            "\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "-------QQ-------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "XXXXXXXXXXX--XXX                XXXXXXXXXXX--XXX\n",
            "\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "----------------                ----------------\n",
            "---------E--S---                ---------E------\n",
            "--------<>-----E                --------<>-----E\n",
            "--------[]----<>                --------[]----<>\n",
            "--------[]----[]                --------[]----[]\n",
            "-EE-E---[]----[]                --------[]----[]\n",
            "XXXXXXXXXXXXXXXX                XXXXXXXXXXXXXXXX\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# trained_vqvae_model = vqvae_trainer.vqvae\n",
        "idx = np.random.choice(len(x_test), 10)\n",
        "test_chunks = x_test[idx]\n",
        "print(idx)\n",
        "reconstructions_test = trained_vqvae_model.predict(test_chunks)\n",
        "\n",
        "print('Original\\t\\t\\tReconstructed')\n",
        "for test_chunk, reconstructed_chunk in zip(test_chunks, reconstructions_test):\n",
        "  reconstructed_chunk_final = reconstructed_chunk.reshape(16, 16, 18)\n",
        "  print(print_side_by_side(test_chunk, reconstructed_chunk_final))\n",
        "  print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hVEZ9700jvk"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eiT3Jmu2LFo"
      },
      "outputs": [],
      "source": [
        "def pad(array, shape):\n",
        "    print(array.shape,shape)\n",
        "    board = np.zeros(shape)\n",
        "    area = [slice(0, array.shape[dim]) for dim in range(array.ndim)]\n",
        "    board[area] = array\n",
        "    return board"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "qVSewdXxtKIS",
        "outputId": "03193d2c-d309-4c08-9d26-a7a36dec070a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-47f720f5f450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mchar_2_tile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mchar_2_tile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-47f720f5f450>\u001b[0m in \u001b[0;36mget_tiles\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mchar_2_tile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchar_2_tile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mchar_2_tile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
          ]
        }
      ],
      "source": [
        "char_2_tile_path = {\n",
        "         \"X\": '/content/drive/MyDrive/pcgml_temp/tiles/X.png',\n",
        "        \"S\" : '/content/drive/MyDrive/pcgml_temp/tiles/S.png',\n",
        "        \"-\" : '/content/drive/MyDrive/pcgml_temp/tiles/-.png',\n",
        "        \"?\" : '/content/drive/MyDrive/pcgml_temp/tiles/Q.png',\n",
        "        \"Q\" : '/content/drive/MyDrive/pcgml_temp/tiles/Q.png',\n",
        "        \"E\" : '/content/drive/MyDrive/pcgml_temp/tiles/E.png',\n",
        "        \"<\" : '/content/drive/MyDrive/pcgml_temp/tiles/PTL.png',\n",
        "        \">\" : '/content/drive/MyDrive/pcgml_temp/tiles/PTR.png',\n",
        "        \"[\" : '/content/drive/MyDrive/pcgml_temp/tiles/[.png',\n",
        "        \"]\" : '/content/drive/MyDrive/pcgml_temp/tiles/].png',\n",
        "        \"o\" : '/content/drive/MyDrive/pcgml_temp/tiles/o.png',\n",
        "        \"B\" : '/content/drive/MyDrive/pcgml_temp/tiles/0.png',\n",
        "        \"b\" : '/content/drive/MyDrive/pcgml_temp/tiles/0.png',\n",
        "        \"#\" : '/content/drive/MyDrive/pcgml_temp/tiles/#.png',\n",
        "        \"D\" : '/content/drive/MyDrive/pcgml_temp/tiles/D.png',\n",
        "        \"H\" : '/content/drive/MyDrive/pcgml_temp/tiles/H.png',\n",
        "        \"M\" : '/content/drive/MyDrive/pcgml_temp/tiles/M.png',\n",
        "        \"T\" : '/content/drive/MyDrive/pcgml_temp/tiles/T.png',\n",
        "        }\n",
        "\n",
        "def get_tiles():\n",
        "  char_2_tile = {}\n",
        "  for char, path in char_2_tile_path.items():\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    char_2_tile[char] = pad(img, shape=(16,16,3))\n",
        "\n",
        "  return char_2_tile\n",
        "\n",
        "char_2_tile = get_tiles()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKzwY_ODyqiw"
      },
      "outputs": [],
      "source": [
        "def visualize(chunk):\n",
        "  img = np.zeros(shape=(16 * 16, 16 * 16, 3))\n",
        "\n",
        "  row_idx = 0\n",
        "  col_idx = 0\n",
        "\n",
        "  for char in chunk:\n",
        "    if char == '\\n':\n",
        "      row_idx += 16\n",
        "      col_idx = 0\n",
        "      continue\n",
        "\n",
        "    img[row_idx:row_idx+16, col_idx:col_idx+16, :] = char_2_tile[char]\n",
        "    col_idx += 16\n",
        "\n",
        "  return img\n",
        "\n",
        "  # image_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  # cv2.imwrite('/content/drive/MyDrive/pcgml_temp/visualize', image_gray)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khx7MGe_z4Md",
        "outputId": "9873e2fe-3d74-42a7-da40-990689cb9d32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee8W1f3mz5sE"
      },
      "outputs": [],
      "source": [
        "sample_input = [\n",
        "    ['-', '-', 'X', 'S'],\n",
        "    ['-', '-', '-', '-'],\n",
        "    ['-', '-', '#', '-'],\n",
        "    ['-', '-', '#', 'E'],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi4srLVpoDpd"
      },
      "outputs": [],
      "source": [
        "def pad(array, shape):\n",
        "    board = np.zeros(shape)\n",
        "    area = [slice(0, array.shape[dim]) for dim in range(array.ndim)]\n",
        "    board[area] = array\n",
        "    return board\n",
        "\n",
        "char_2_tile_path = {\n",
        "         \"X\": '/content/drive/MyDrive/pcgml_temp/tiles/X.png',\n",
        "        \"S\" : '/content/drive/MyDrive/pcgml_temp/tiles/S.png',\n",
        "        \"-\" : '/content/drive/MyDrive/pcgml_temp/tiles/-.png',\n",
        "        \"?\" : '/content/drive/MyDrive/pcgml_temp/tiles/Q.png',\n",
        "        \"Q\" : '/content/drive/MyDrive/pcgml_temp/tiles/Q.png',\n",
        "        \"E\" : '/content/drive/MyDrive/pcgml_temp/tiles/E.png',\n",
        "        \"<\" : '/content/drive/MyDrive/pcgml_temp/tiles/PTL.png',\n",
        "        \">\" : '/content/drive/MyDrive/pcgml_temp/tiles/PTR.png',\n",
        "        \"[\" : '/content/drive/MyDrive/pcgml_temp/tiles/[.png',\n",
        "        \"]\" : '/content/drive/MyDrive/pcgml_temp/tiles/].png',\n",
        "        \"o\" : '/content/drive/MyDrive/pcgml_temp/tiles/o.png',\n",
        "        \"B\" : '/content/drive/MyDrive/pcgml_temp/tiles/0.png',\n",
        "        \"b\" : '/content/drive/MyDrive/pcgml_temp/tiles/0.png',\n",
        "        \"#\" : '/content/drive/MyDrive/pcgml_temp/tiles/#.png',\n",
        "        \"D\" : '/content/drive/MyDrive/pcgml_temp/tiles/D.png',\n",
        "        \"H\" : '/content/drive/MyDrive/pcgml_temp/tiles/H.png',\n",
        "        \"M\" : '/content/drive/MyDrive/pcgml_temp/tiles/M.png',\n",
        "        \"T\" : '/content/drive/MyDrive/pcgml_temp/tiles/T.png',\n",
        "        }\n",
        "\n",
        "def get_tiles():\n",
        "  char_2_tile = {}\n",
        "  for char, path in char_2_tile_path.items():\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    char_2_tile[char] = pad(img, shape=(16,16,3))\n",
        "\n",
        "  return char_2_tile\n",
        "\n",
        "char_2_tile = get_tiles()\n",
        "\n",
        "def visualize_ga(chunk):\n",
        "  img = np.zeros(shape=(14 * 16, 16 * 16, 3))\n",
        "\n",
        "  row_idx = 0\n",
        "  col_idx = 0\n",
        "\n",
        "  for row in chunk:\n",
        "    for char in row:\n",
        "      img[row_idx:row_idx+16, col_idx:col_idx+16, :] = char_2_tile[char]\n",
        "      col_idx += 16\n",
        "    row_idx += 16\n",
        "    col_idx = 0\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUCz5DM6o0C5",
        "outputId": "1ae4d438-c719-48dc-8731-1fc38a84ed43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(224, 256, 3)"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoJkftIfo4Y_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
